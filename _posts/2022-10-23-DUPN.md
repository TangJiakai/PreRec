---
layout: post
title: DUPN
tags: [多主任务, 任务迁移, 有监督]
---

[Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks](https://dl.acm.org/doi/abs/10.1145/3219819.3219828)
# 方法概括
Deep User Perception Network(DUPN)是可分解模型。
1. 第一部分利用多种任务（CTR，L2R，PPP，FIFP）端到端联合学习用户通用表征。
2. 子任务的预测推断。实际上线预测时，只需要跑1次第一部分模型得到用户表征，接着作用到各种下游任务上，虽然物品很多，但是由于该部分模型较小，因此效率高。
3. 实际上线，可进行模型增量更新

# 模型介绍
第一部分模型输入$x_i=<item_i,property_i>$
- $item_i$包括generalized features和personalized feature：generalized features为[shop ID，brand，category，item tags(item attribute+statistical features)]；personalized feature为[item ID]。
- $property_i$包括behavior type, behavior scenario and behavior time：behavior type为click, bookmark, add to cart and purchase；behavior scenario为search, recommender scenario or advertising；behavior time包括time gap between the behavior and current search,
workdays or weekends, in the morning or at night等。

![](/PreRec_CDR/assets/fig/3.png)

第二部分模型输入item embedding类 或 ranking features

![](/PreRec_CDR/assets/fig/4.png)



# 实验
- 离线不同方法比较
- 单任务与多任务对比
- 表征迁移能力：使用新任务SPP检验表征迁移能力。迁移过程分为单任务重训练、多任务重训练、网络微调（增加下游预测层+单任务训练+元模型初始化参数）、**表征迁移（增加简单下游预测网络）**。
- 消融分析
- 在线A/B测试

---
# Question
- 多任务同时预测？（因为CTR和PPP的输出要作为L2R的输入，不太可能并行输出预测结果）
- 下图中的AUC和loss是在哪个子数据集上的表现？(训练、验证、测试)

![](/PreRec_CDR/assets/fig/1.png)
- 下图中如何计算得到强度值？

![](/PreRec_CDR/assets/fig/2.png)