---
layout: post
title: $S^3$-Rec
tags: [多辅任务, 自监督]
---
[$S^3$-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization](https://dl.acm.org/doi/abs/10.1145/3340531.3411954)

# 方法概括
1. 利用互信息最大化MIM巧妙设计四个任务，实现自监督预训练范式的数据表征增强，提升序列推荐性能。
2. 四个子任务：APP(相关属性预测，物品-属性)+MIP(掩码物品预测，序列-物品)+MAP(掩码属性预测，序列-属性)+SP(子段预测，序列-子序列)。旨在以统一的方式刻画不同细粒度或者不同角度之间的本质联系。
3. 算法分为预训练+微调阶段。预训练即四个任务(基模型-双向Transfrom)，微调即用预训练的参数初始化模型(单向Transform)后根据具体下游任务训练。

# 模型介绍
![](/PreRec_CDR/assets/fig/6.png)

# 实验
- 与11个baseline比较
- 消融实验。分别去掉四个子任务
- 应用提出方法到其他basemodel验证性能提升
- 验证不同数据量情况下，S3Rec仍能提升表现
- 预训练阶段较少迭代就能大幅度提升最终模型表现（通过对比不同迭代次数下的微调模型表现）
- 预训练提高微调阶段的收敛速度


---
# Qestions
- 为什么最小化如下式子（不应该是最大化？）

![](/PreRec_CDR/assets/fig/5.png)